{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import onnxruntime\n",
    "import tensorflow as tf\n",
    "import onnx2tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[449.8624,  73.7949, 640.0000, 595.1772],\n",
       "          [ 23.0561,  70.3881, 188.5582, 389.9374],\n",
       "          [412.3035,  96.0241, 621.5682, 360.9136],\n",
       "          [443.1876, 274.0103, 630.7805, 539.3550],\n",
       "          [344.7103,  52.3481, 634.7700, 457.2322],\n",
       "          [ 10.9015,  94.8681, 287.9455, 560.0727],\n",
       "          [  2.4115,  56.7143, 136.1261, 593.2604],\n",
       "          [315.6378, 257.7193, 640.0000, 608.1486],\n",
       "          [ 20.4525, 212.2023, 189.1365, 552.5846]], grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       "  'scores': tensor([0.0941, 0.0701, 0.0619, 0.0593, 0.0584, 0.0584, 0.0575, 0.0524, 0.0500],\n",
       "         grad_fn=<IndexBackward0>)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/faster_not_jit_rcnn_model.pt', map_location='cpu')\n",
    "img_size = (640, 640)\n",
    "batch_size = 1\n",
    "onnx_model_path = 'model.onnx'\n",
    "sample_input = Variable(torch.rand((batch_size, 3, *img_size)))\n",
    "\n",
    "y = model(sample_input)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    sample_input, \n",
    "    onnx_model_path,\n",
    "    verbose=False,\n",
    "    input_names=['images'], \n",
    "    output_names=['boxes', 'labels', 'scores'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONNX] Model Outputs: ['boxes', 'labels', 'scores']\n",
      "[ONNX] Model Predictions: [array([[447.12375  ,  65.44785  , 640.       , 569.8071   ],\n",
      "       [  4.3053346,  89.29026  , 179.57637  , 590.9504   ],\n",
      "       [466.1367   ,  93.82244  , 640.       , 328.62137  ],\n",
      "       [ 14.015589 , 100.30181  , 303.46906  , 304.37463  ],\n",
      "       [365.2206   ,  89.331665 , 617.82794  , 363.25873  ]],\n",
      "      dtype=float32), array([2, 2, 2, 2, 2], dtype=int64), array([0.0831432 , 0.06551051, 0.06000041, 0.05850454, 0.05648219],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(\"model.onnx\")\n",
    "onnx_output = session.run([\"boxes\", 'labels', 'scores'], {\"images\": torch.rand((1, 3, 640,640)).numpy()})\n",
    "print(\"[ONNX] Model Outputs:\", [o.name for o in session.get_outputs()])\n",
    "print(\"[ONNX] Model Predictions:\", onnx_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x1f210a745d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx2tf.convert(\n",
    "    input_onnx_file_path=\"model.onnx\",\n",
    "    output_folder_path=\"saved_model\",\n",
    "    copy_onnx_input_output_names_to_tflite=True,\n",
    "    non_verbose=True,\n",
    "    output_keras_v3=True,\n",
    "    param_replacement_file=\"param_replacement.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'inputs_0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 640, 640,   3]),\n",
       "  'shape_signature': array([  1, 640, 640,   3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, test the newer TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"saved_model/model_float32.tflite\")\n",
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load the TensorFlow Lite model\n",
    "# tflite_model_path = \"model/model_float32.tflite\"\n",
    "# interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "# interpreter.allocate_tensors()\n",
    "\n",
    "# # Get input and output details\n",
    "# input_details = interpreter.get_input_details()\n",
    "# output_details = interpreter.get_output_details()\n",
    "\n",
    "# # Prepare and input data (replace with your actual input data)\n",
    "# input_data = torch.rand(1, 640, 640, 3)\n",
    "\n",
    "# # Set the input tensor with your data\n",
    "# interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# # Run the inference\n",
    "# interpreter.invoke()\n",
    "\n",
    "# # Get the output tensor\n",
    "# output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# # Output data contains the model's predictions\n",
    "# print(\"[TFLite] Model Predictions:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
